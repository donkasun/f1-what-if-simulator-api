{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 What-If Simulator: Data Exploration and Training\n",
    "\n",
    "This notebook connects to the OpenF1 API to explore Formula 1 data and prepare it for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import httpx\n",
    "from typing import Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Base URL\n",
    "OPENF1_BASE_URL = \"https://api.openf1.org/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find a Race Session\n",
    "\n",
    "Our goal is to programmatically find the session_key for a specific, complete race event. We will use the 'Bahrain' Grand Prix from the 2023 season as our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Finding Bahrain 2023 meeting...\n",
      "Found Bahrain meeting with key: 1141\n",
      "\n",
      "Step 2: Finding Race session...\n",
      "Found Race session with key: 7953\n",
      "\n",
      "Final session_key: 7953\n"
     ]
    }
   ],
   "source": [
    "async def fetch_session_key() -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Fetch the session_key for the Bahrain Grand Prix 2023 Race session.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The session_key if found, None otherwise\n",
    "    \"\"\"\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        try:\n",
    "            # Step 1: Find the meeting_key for Bahrain 2023\n",
    "            print(\"Step 1: Finding Bahrain 2023 meeting...\")\n",
    "            meetings_response = await client.get(\n",
    "                f\"{OPENF1_BASE_URL}/meetings?year=2023\"\n",
    "            )\n",
    "            meetings_response.raise_for_status()\n",
    "            meetings_data = meetings_response.json()\n",
    "\n",
    "            # Find Bahrain meeting\n",
    "            bahrain_meeting = None\n",
    "            for meeting in meetings_data:\n",
    "                if \"bahrain\" in meeting.get(\"meeting_name\", \"\").lower():\n",
    "                    bahrain_meeting = meeting\n",
    "                    break\n",
    "\n",
    "            if not bahrain_meeting:\n",
    "                print(\"Error: Bahrain meeting not found in 2023\")\n",
    "                return None\n",
    "\n",
    "            meeting_key = bahrain_meeting[\"meeting_key\"]\n",
    "            print(f\"Found Bahrain meeting with key: {meeting_key}\")\n",
    "\n",
    "            # Step 2: Find the Race session for this meeting\n",
    "            print(\"\\nStep 2: Finding Race session...\")\n",
    "            sessions_response = await client.get(\n",
    "                f\"{OPENF1_BASE_URL}/sessions?meeting_key={meeting_key}\"\n",
    "            )\n",
    "            sessions_response.raise_for_status()\n",
    "            sessions_data = sessions_response.json()\n",
    "\n",
    "            # Find Race session\n",
    "            race_session = None\n",
    "            for session in sessions_data:\n",
    "                if session.get(\"session_name\", \"\").lower() == \"race\":\n",
    "                    race_session = session\n",
    "                    break\n",
    "\n",
    "            if not race_session:\n",
    "                print(\"Error: Race session not found for Bahrain 2023\")\n",
    "                return None\n",
    "\n",
    "            session_key = race_session[\"session_key\"]\n",
    "            print(f\"Found Race session with key: {session_key}\")\n",
    "\n",
    "            return session_key\n",
    "\n",
    "        except httpx.HTTPStatusError as e:\n",
    "            print(f\"HTTP error occurred: {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "# Execute the function\n",
    "session_key = await fetch_session_key()\n",
    "print(f\"\\nFinal session_key: {session_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Race Data\n",
    "\n",
    "Now that we have the race session_key, let's fetch the essential data for our simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for session_key: 7953\n",
      "\n",
      "Fetching lap data...\n",
      "Fetching pit stop data...\n",
      "Fetching driver information...\n",
      "\n",
      "Data fetching completed successfully!\n"
     ]
    }
   ],
   "source": [
    "async def fetch_race_data(session_key: str) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Fetch race data from OpenF1 API and return as DataFrames.\n",
    "\n",
    "    Args:\n",
    "        session_key (str): The session key for the race\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, pd.DataFrame]: Dictionary containing 'laps', 'pit', and 'drivers' DataFrames\n",
    "    \"\"\"\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        try:\n",
    "            print(f\"Fetching data for session_key: {session_key}\")\n",
    "\n",
    "            # Fetch lap data\n",
    "            print(\"\\nFetching lap data...\")\n",
    "            laps_response = await client.get(\n",
    "                f\"{OPENF1_BASE_URL}/laps?session_key={session_key}\"\n",
    "            )\n",
    "            laps_response.raise_for_status()\n",
    "            laps_data = laps_response.json()\n",
    "            laps_df = pd.DataFrame(laps_data)\n",
    "\n",
    "            # Fetch pit stop data\n",
    "            print(\"Fetching pit stop data...\")\n",
    "            pit_response = await client.get(\n",
    "                f\"{OPENF1_BASE_URL}/pit?session_key={session_key}\"\n",
    "            )\n",
    "            pit_response.raise_for_status()\n",
    "            pit_data = pit_response.json()\n",
    "            pit_df = pd.DataFrame(pit_data)\n",
    "\n",
    "            # Fetch driver information\n",
    "            print(\"Fetching driver information...\")\n",
    "            drivers_response = await client.get(\n",
    "                f\"{OPENF1_BASE_URL}/drivers?session_key={session_key}\"\n",
    "            )\n",
    "            drivers_response.raise_for_status()\n",
    "            drivers_data = drivers_response.json()\n",
    "            drivers_df = pd.DataFrame(drivers_data)\n",
    "\n",
    "            print(\"\\nData fetching completed successfully!\")\n",
    "\n",
    "            return {\"laps\": laps_df, \"pit\": pit_df, \"drivers\": drivers_df}\n",
    "\n",
    "        except httpx.HTTPStatusError as e:\n",
    "            print(f\"HTTP error occurred: {e}\")\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}\")\n",
    "            return {}\n",
    "\n",
    "\n",
    "# Execute the function\n",
    "if session_key:\n",
    "    race_data = await fetch_race_data(session_key)\n",
    "\n",
    "    # Extract DataFrames\n",
    "    laps_df = race_data.get(\"laps\", pd.DataFrame())\n",
    "    pit_df = race_data.get(\"pit\", pd.DataFrame())\n",
    "    drivers_df = race_data.get(\"drivers\", pd.DataFrame())\n",
    "else:\n",
    "    print(\"Cannot fetch race data without a valid session_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Review\n",
    "\n",
    "Let's examine the structure, columns, and data types of our three DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "LAP DATA REVIEW\n",
      "==================================================\n",
      "\n",
      "First 5 rows:\n",
      "   meeting_key  session_key  driver_number  lap_number  \\\n",
      "0         1141         7953              1           2   \n",
      "1         1141         7953             16           2   \n",
      "2         1141         7953             11           2   \n",
      "3         1141         7953             55           2   \n",
      "4         1141         7953             44           2   \n",
      "\n",
      "                         date_start  duration_sector_1  duration_sector_2  \\\n",
      "0  2023-03-05T15:05:17.858000+00:00             31.342             42.504   \n",
      "1  2023-03-05T15:05:19.108000+00:00             31.407             43.127   \n",
      "2  2023-03-05T15:05:19.904000+00:00             31.532             43.116   \n",
      "3  2023-03-05T15:05:20.529000+00:00             31.451             43.164   \n",
      "4  2023-03-05T15:05:21.139000+00:00             31.408             43.352   \n",
      "\n",
      "   duration_sector_3  i1_speed  i2_speed  is_pit_out_lap  lap_duration  \\\n",
      "0                NaN     227.0       238           False           NaN   \n",
      "1             24.216       NaN       243           False        98.750   \n",
      "2             24.214     228.0       238           False        98.862   \n",
      "3             24.318     229.0       242           False        98.933   \n",
      "4             24.406       NaN       247           False        99.166   \n",
      "\n",
      "                                   segments_sector_1  \\\n",
      "0  [2049, 2049, 2049, 2049, 2051, 2049, 2049, 204...   \n",
      "1  [2049, 2049, 2049, 2049, 2049, 2049, 2049, 204...   \n",
      "2  [2049, 2049, 2049, 2049, 2049, 2049, 2048, 204...   \n",
      "3  [2049, 2049, 2049, 2049, 2049, 2049, 2049, 204...   \n",
      "4  [2049, 2049, 2049, 2049, 2049, 2049, 2048, 204...   \n",
      "\n",
      "                                   segments_sector_2  \\\n",
      "0  [2048, 2049, 2048, 2049, 2048, 2049, 2049, 204...   \n",
      "1  [2048, 2048, 2048, 2048, 2048, 2048, 2048, 204...   \n",
      "2  [2049, 2049, 2049, 2048, 2049, 2048, 2048, 204...   \n",
      "3  [2049, 2051, 2049, 2049, 2049, 2048, 2048, 204...   \n",
      "4  [2049, 2048, 2048, 2049, 2049, 2049, 2049, 204...   \n",
      "\n",
      "                            segments_sector_3  st_speed  \n",
      "0                       [0, 0, 0, 0, 0, 0, 0]     288.0  \n",
      "1     [2048, 2049, 2048, 2049, 2049, 2048, 0]     294.0  \n",
      "2  [2048, 2048, 2048, 2048, 2048, 2048, 2049]     283.0  \n",
      "3  [2048, 2048, 2048, 2049, 2048, 2048, 2049]     299.0  \n",
      "4  [2049, 2048, 2048, 2048, 2048, 2048, 2048]     311.0  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1056 entries, 0 to 1055\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   meeting_key        1056 non-null   int64  \n",
      " 1   session_key        1056 non-null   int64  \n",
      " 2   driver_number      1056 non-null   int64  \n",
      " 3   lap_number         1056 non-null   int64  \n",
      " 4   date_start         1036 non-null   object \n",
      " 5   duration_sector_1  1032 non-null   float64\n",
      " 6   duration_sector_2  1056 non-null   float64\n",
      " 7   duration_sector_3  1053 non-null   float64\n",
      " 8   i1_speed           799 non-null    float64\n",
      " 9   i2_speed           1056 non-null   int64  \n",
      " 10  is_pit_out_lap     1056 non-null   bool   \n",
      " 11  lap_duration       1029 non-null   float64\n",
      " 12  segments_sector_1  1056 non-null   object \n",
      " 13  segments_sector_2  1056 non-null   object \n",
      " 14  segments_sector_3  1056 non-null   object \n",
      " 15  st_speed           902 non-null    float64\n",
      "dtypes: bool(1), float64(6), int64(5), object(4)\n",
      "memory usage: 124.9+ KB\n",
      "None\n",
      "\n",
      "Shape: (1056, 16)\n",
      "Columns: ['meeting_key', 'session_key', 'driver_number', 'lap_number', 'date_start', 'duration_sector_1', 'duration_sector_2', 'duration_sector_3', 'i1_speed', 'i2_speed', 'is_pit_out_lap', 'lap_duration', 'segments_sector_1', 'segments_sector_2', 'segments_sector_3', 'st_speed']\n"
     ]
    }
   ],
   "source": [
    "# Review Lap Data\n",
    "print(\"=\" * 50)\n",
    "print(\"LAP DATA REVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(laps_df.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(laps_df.info())\n",
    "print(f\"\\nShape: {laps_df.shape}\")\n",
    "print(f\"Columns: {list(laps_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "PIT STOP DATA REVIEW\n",
      "==================================================\n",
      "\n",
      "First 5 rows:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Empty DataFrame\n",
      "None\n",
      "\n",
      "Shape: (0, 0)\n",
      "Columns: []\n"
     ]
    }
   ],
   "source": [
    "# Review Pit Stop Data\n",
    "print(\"=\" * 50)\n",
    "print(\"PIT STOP DATA REVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(pit_df.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(pit_df.info())\n",
    "print(f\"\\nShape: {pit_df.shape}\")\n",
    "print(f\"Columns: {list(pit_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "DRIVER DATA REVIEW\n",
      "==================================================\n",
      "\n",
      "First 5 rows:\n",
      "   meeting_key  session_key  driver_number broadcast_name       full_name  \\\n",
      "0         1141         7953              1   M VERSTAPPEN  Max VERSTAPPEN   \n",
      "1         1141         7953              2     L SARGEANT  Logan SARGEANT   \n",
      "2         1141         7953              4       L NORRIS    Lando NORRIS   \n",
      "3         1141         7953             10        P GASLY    Pierre GASLY   \n",
      "4         1141         7953             11        S PEREZ    Sergio PEREZ   \n",
      "\n",
      "  name_acronym        team_name team_colour first_name   last_name  \\\n",
      "0          VER  Red Bull Racing      3671C6        Max  Verstappen   \n",
      "1          SAR         Williams      37BEDD      Logan    Sargeant   \n",
      "2          NOR          McLaren      F58020      Lando      Norris   \n",
      "3          GAS           Alpine      2293D1     Pierre       Gasly   \n",
      "4          PER  Red Bull Racing      3671C6     Sergio       Perez   \n",
      "\n",
      "                                        headshot_url country_code  \n",
      "0  https://www.formula1.com/content/dam/fom-websi...          NED  \n",
      "1  https://www.formula1.com/content/dam/fom-websi...          USA  \n",
      "2  https://www.formula1.com/content/dam/fom-websi...          GBR  \n",
      "3  https://www.formula1.com/content/dam/fom-websi...          FRA  \n",
      "4  https://www.formula1.com/content/dam/fom-websi...          MEX  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   meeting_key     20 non-null     int64 \n",
      " 1   session_key     20 non-null     int64 \n",
      " 2   driver_number   20 non-null     int64 \n",
      " 3   broadcast_name  20 non-null     object\n",
      " 4   full_name       20 non-null     object\n",
      " 5   name_acronym    20 non-null     object\n",
      " 6   team_name       20 non-null     object\n",
      " 7   team_colour     20 non-null     object\n",
      " 8   first_name      20 non-null     object\n",
      " 9   last_name       20 non-null     object\n",
      " 10  headshot_url    20 non-null     object\n",
      " 11  country_code    20 non-null     object\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 2.0+ KB\n",
      "None\n",
      "\n",
      "Shape: (20, 12)\n",
      "Columns: ['meeting_key', 'session_key', 'driver_number', 'broadcast_name', 'full_name', 'name_acronym', 'team_name', 'team_colour', 'first_name', 'last_name', 'headshot_url', 'country_code']\n"
     ]
    }
   ],
   "source": [
    "# Review Driver Data\n",
    "print(\"=\" * 50)\n",
    "print(\"DRIVER DATA REVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(drivers_df.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(drivers_df.info())\n",
    "print(f\"\\nShape: {drivers_df.shape}\")\n",
    "print(f\"Columns: {list(drivers_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We have successfully:\n",
    "1. Connected to the OpenF1 API\n",
    "2. Found the session_key for the Bahrain Grand Prix 2023 Race\n",
    "3. Fetched lap data, pit stop data, and driver information\n",
    "4. Reviewed the structure and content of our datasets\n",
    "\n",
    "This data will serve as the foundation for our F1 simulation model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Now we will prepare our features for the machine learning model. Our initial model will be simple, focusing on the most important predictors of lap times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature engineering...\n",
      "Initial laps DataFrame shape: (1056, 16)\n",
      "Warning: Missing columns: ['tyre_compound', 'lap_time']\n",
      "Available columns: ['meeting_key', 'session_key', 'driver_number', 'lap_number', 'date_start', 'duration_sector_1', 'duration_sector_2', 'duration_sector_3', 'i1_speed', 'i2_speed', 'is_pit_out_lap', 'lap_duration', 'segments_sector_1', 'segments_sector_2', 'segments_sector_3', 'st_speed']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['tyre_compound'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAll required columns found!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Create feature DataFrame with selected columns\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m X = \u001b[43mlaps_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_columns\u001b[49m\u001b[43m]\u001b[49m.copy()\n\u001b[32m     19\u001b[39m y = laps_df[target_column].copy()\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFeature DataFrame shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['tyre_compound'] not in index\""
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "print(\"Starting feature engineering...\")\n",
    "print(f\"Initial laps DataFrame shape: {laps_df.shape}\")\n",
    "\n",
    "# Print available columns for reference\n",
    "print(f\"Available columns: {list(laps_df.columns)}\")\n",
    "\n",
    "# Use available columns - 'lap_duration' instead of 'lap_time' and realistic features\n",
    "feature_columns = [\"lap_number\", \"driver_number\", \"i2_speed\", \"st_speed\"]\n",
    "target_column = \"lap_duration\"\n",
    "\n",
    "# Check if required columns exist\n",
    "missing_columns = [\n",
    "    col for col in feature_columns + [target_column] if col not in laps_df.columns\n",
    "]\n",
    "if missing_columns:\n",
    "    print(f\"Warning: Missing columns: {missing_columns}\")\n",
    "    print(\"Available columns are shown above. Adjusting feature selection...\")\n",
    "else:\n",
    "    print(\"All required columns found!\")\n",
    "\n",
    "# Create feature DataFrame with selected columns that exist\n",
    "available_features = [col for col in feature_columns if col in laps_df.columns]\n",
    "print(f\"\\nUsing available features: {available_features}\")\n",
    "\n",
    "X = laps_df[available_features].copy()\n",
    "y = laps_df[target_column].copy()\n",
    "\n",
    "print(f\"\\nFeature DataFrame shape: {X.shape}\")\n",
    "print(f\"Target Series shape: {y.shape}\")\n",
    "\n",
    "# Handle missing values\n",
    "print(\"\\nHandling missing values...\")\n",
    "print(f\"Missing values in target: {y.isnull().sum()}\")\n",
    "print(\"Missing values in features:\")\n",
    "for col in X.columns:\n",
    "    print(f\"  {col}: {X[col].isnull().sum()}\")\n",
    "\n",
    "# Drop rows where lap_duration is null or any feature is null\n",
    "valid_indices = y.notna() & X.notna().all(axis=1)\n",
    "X_clean = X[valid_indices].copy()\n",
    "y_clean = y[valid_indices].copy()\n",
    "\n",
    "print(f\"\\nAfter cleaning - X shape: {X_clean.shape}, y shape: {y_clean.shape}\")\n",
    "print(f\"Data loss: {len(y) - len(y_clean)} rows dropped due to missing values\")\n",
    "\n",
    "# Display sample of final data\n",
    "print(\"\\nSample of final features:\")\n",
    "print(X_clean.head())\n",
    "print(\"\\nSample of target values (lap_duration in seconds):\")\n",
    "print(y_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Now we will train a baseline machine learning model to predict lap times. We'll use LightGBM, which is excellent for tabular data and provides good performance with minimal hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lightgbm/lib/lib_lightgbm.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\n  Referenced from: <D44045CD-B874-3A27-9A61-F131D99AACE4> /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lightgbm/lib/lib_lightgbm.dylib\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Model Training\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LGBMRegressor\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lightgbm/__init__.py:11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# .basic is intentionally loaded as early as possible, to dlopen() lib_lightgbm.{dll,dylib,so}\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# and its dependencies as early as possible\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbasic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Booster, Dataset, Sequence, register_logger\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopException, early_stopping, log_evaluation, record_evaluation, reset_parameter\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CVBooster, cv, train\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lightgbm/basic.py:9\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33;03m\"\"\"Wrapper for C API of LightGBM.\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# This import causes lib_lightgbm.{dll,dylib,so} to be loaded.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# It's intentionally done here, as early as possible, to avoid issues like\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# \"libgomp.so.1: cannot allocate memory in static TLS block\" on aarch64 Linux.\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# For details, see the \"cannot allocate memory in static TLS block\" entry in docs/FAQ.rst.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlibpath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB  \u001b[38;5;66;03m# isort: skip\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mabc\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mctypes\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lightgbm/libpath.py:49\u001b[39m\n\u001b[32m     47\u001b[39m     _LIB = Mock(ctypes.CDLL)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     _LIB = \u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcdll\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLoadLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_find_lib_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ctypes/__init__.py:460\u001b[39m, in \u001b[36mLibraryLoader.LoadLibrary\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mLoadLibrary\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dlltype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ctypes/__init__.py:379\u001b[39m, in \u001b[36mCDLL.__init__\u001b[39m\u001b[34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[39m\n\u001b[32m    376\u001b[39m \u001b[38;5;28mself\u001b[39m._FuncPtr = _FuncPtr\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle = \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    381\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle = handle\n",
      "\u001b[31mOSError\u001b[39m: dlopen(/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lightgbm/lib/lib_lightgbm.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\n  Referenced from: <D44045CD-B874-3A27-9A61-F131D99AACE4> /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/lightgbm/lib/lib_lightgbm.dylib\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file)"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "print(f\"Training data shape: {X_clean.shape}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_clean, y_clean, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "\n",
    "# Initialize the model\n",
    "model = LGBMRegressor(\n",
    "    random_state=42,\n",
    "    verbose=-1,  # Suppress verbose output\n",
    ")\n",
    "\n",
    "print(\"\\nTraining LightGBM model...\")\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training completed!\")\n",
    "print(f\"Number of features used: {model.n_features_in_}\")\n",
    "print(f\"Feature names: {list(model.feature_name_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation & Saving\n",
    "\n",
    "Now we will evaluate the model's performance and save it for use in our API. We'll calculate the Root Mean Squared Error (RMSE) to assess prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation & Saving\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(\"Evaluating model performance...\")\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f} seconds\")\n",
    "\n",
    "# Calculate additional metrics\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f} seconds\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared (R²): {r2:.4f}\")\n",
    "\n",
    "# Display some sample predictions\n",
    "print(\"\\nSample predictions vs actual:\")\n",
    "comparison_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Actual\": y_test.head(10),\n",
    "        \"Predicted\": y_pred[:10],\n",
    "        \"Difference\": y_test.head(10) - y_pred[:10],\n",
    "    }\n",
    ")\n",
    "print(comparison_df)\n",
    "\n",
    "# Save the model\n",
    "print(\"\\nSaving the trained model...\")\n",
    "model_path = \"../app/models/lap_time_predictor.joblib\"\n",
    "\n",
    "# Create the models directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"Model saved successfully to: {model_path}\")\n",
    "\n",
    "# Verify the model can be loaded\n",
    "print(\"\\nVerifying model can be loaded...\")\n",
    "loaded_model = joblib.load(model_path)\n",
    "test_prediction = loaded_model.predict(X_test.head(1))\n",
    "print(f\"Test prediction from loaded model: {test_prediction[0]:.4f} seconds\")\n",
    "print(\"Model loading verification successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary\n",
    "\n",
    "We have successfully:\n",
    "1. ✅ Connected to the OpenF1 API and fetched race data\n",
    "2. ✅ Engineered features for lap time prediction\n",
    "3. ✅ Trained a LightGBM regression model\n",
    "4. ✅ Evaluated model performance with RMSE metric\n",
    "5. ✅ Saved the trained model for API use\n",
    "\n",
    "The baseline model is now ready to be used by our F1 What-If Simulator API for predicting lap times based on lap number, driver number, and tyre compound."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
