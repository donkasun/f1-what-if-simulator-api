{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 What-If Simulator: Data Exploration and Training\n",
    "\n",
    "This notebook connects to the OpenF1 API to explore Formula 1 data and prepare it for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import httpx\n",
    "import asyncio\n",
    "from typing import Dict, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Base URL\n",
    "OPENF1_BASE_URL = \"https://api.openf1.org/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find a Race Session\n",
    "\n",
    "Our goal is to programmatically find the session_key for a specific, complete race event. We will use the 'Bahrain' Grand Prix from the 2023 season as our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_session_key() -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Fetch the session_key for the Bahrain Grand Prix 2023 Race session.\n",
    "    \n",
    "    Returns:\n",
    "        Optional[str]: The session_key if found, None otherwise\n",
    "    \"\"\"\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        try:\n",
    "            # Step 1: Find the meeting_key for Bahrain 2023\n",
    "            print(\"Step 1: Finding Bahrain 2023 meeting...\")\n",
    "            meetings_response = await client.get(f\"{OPENF1_BASE_URL}/meetings?year=2023\")\n",
    "            meetings_response.raise_for_status()\n",
    "            meetings_data = meetings_response.json()\n",
    "            \n",
    "            # Find Bahrain meeting\n",
    "            bahrain_meeting = None\n",
    "            for meeting in meetings_data:\n",
    "                if meeting.get('meeting_name', '').lower() == 'bahrain':\n",
    "                    bahrain_meeting = meeting\n",
    "                    break\n",
    "            \n",
    "            if not bahrain_meeting:\n",
    "                print(\"Error: Bahrain meeting not found in 2023\")\n",
    "                return None\n",
    "            \n",
    "            meeting_key = bahrain_meeting['meeting_key']\n",
    "            print(f\"Found Bahrain meeting with key: {meeting_key}\")\n",
    "            \n",
    "            # Step 2: Find the Race session for this meeting\n",
    "            print(\"\\nStep 2: Finding Race session...\")\n",
    "            sessions_response = await client.get(f\"{OPENF1_BASE_URL}/sessions?meeting_key={meeting_key}\")\n",
    "            sessions_response.raise_for_status()\n",
    "            sessions_data = sessions_response.json()\n",
    "            \n",
    "            # Find Race session\n",
    "            race_session = None\n",
    "            for session in sessions_data:\n",
    "                if session.get('session_name', '').lower() == 'race':\n",
    "                    race_session = session\n",
    "                    break\n",
    "            \n",
    "            if not race_session:\n",
    "                print(\"Error: Race session not found for Bahrain 2023\")\n",
    "                return None\n",
    "            \n",
    "            session_key = race_session['session_key']\n",
    "            print(f\"Found Race session with key: {session_key}\")\n",
    "            \n",
    "            return session_key\n",
    "            \n",
    "        except httpx.HTTPStatusError as e:\n",
    "            print(f\"HTTP error occurred: {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "# Execute the function\n",
    "session_key = await fetch_session_key()\n",
    "print(f\"\\nFinal session_key: {session_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Race Data\n",
    "\n",
    "Now that we have the race session_key, let's fetch the essential data for our simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_race_data(session_key: str) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Fetch race data from OpenF1 API and return as DataFrames.\n",
    "    \n",
    "    Args:\n",
    "        session_key (str): The session key for the race\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, pd.DataFrame]: Dictionary containing 'laps', 'pit', and 'drivers' DataFrames\n",
    "    \"\"\"\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        try:\n",
    "            print(f\"Fetching data for session_key: {session_key}\")\n",
    "            \n",
    "            # Fetch lap data\n",
    "            print(\"\\nFetching lap data...\")\n",
    "            laps_response = await client.get(f\"{OPENF1_BASE_URL}/laps?session_key={session_key}\")\n",
    "            laps_response.raise_for_status()\n",
    "            laps_data = laps_response.json()\n",
    "            laps_df = pd.DataFrame(laps_data)\n",
    "            \n",
    "            # Fetch pit stop data\n",
    "            print(\"Fetching pit stop data...\")\n",
    "            pit_response = await client.get(f\"{OPENF1_BASE_URL}/pit?session_key={session_key}\")\n",
    "            pit_response.raise_for_status()\n",
    "            pit_data = pit_response.json()\n",
    "            pit_df = pd.DataFrame(pit_data)\n",
    "            \n",
    "            # Fetch driver information\n",
    "            print(\"Fetching driver information...\")\n",
    "            drivers_response = await client.get(f\"{OPENF1_BASE_URL}/drivers?session_key={session_key}\")\n",
    "            drivers_response.raise_for_status()\n",
    "            drivers_data = drivers_response.json()\n",
    "            drivers_df = pd.DataFrame(drivers_data)\n",
    "            \n",
    "            print(\"\\nData fetching completed successfully!\")\n",
    "            \n",
    "            return {\n",
    "                'laps': laps_df,\n",
    "                'pit': pit_df,\n",
    "                'drivers': drivers_df\n",
    "            }\n",
    "            \n",
    "        except httpx.HTTPStatusError as e:\n",
    "            print(f\"HTTP error occurred: {e}\")\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}\")\n",
    "            return {}\n",
    "\n",
    "# Execute the function\n",
    "if session_key:\n",
    "    race_data = await fetch_race_data(session_key)\n",
    "    \n",
    "    # Extract DataFrames\n",
    "    laps_df = race_data.get('laps', pd.DataFrame())\n",
    "    pit_df = race_data.get('pit', pd.DataFrame())\n",
    "    drivers_df = race_data.get('drivers', pd.DataFrame())\n",
    "else:\n",
    "    print(\"Cannot fetch race data without a valid session_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Review\n",
    "\n",
    "Let's examine the structure, columns, and data types of our three DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review Lap Data\n",
    "print(\"=\" * 50)\n",
    "print(\"LAP DATA REVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(laps_df.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(laps_df.info())\n",
    "print(f\"\\nShape: {laps_df.shape}\")\n",
    "print(f\"Columns: {list(laps_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review Pit Stop Data\n",
    "print(\"=\" * 50)\n",
    "print(\"PIT STOP DATA REVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(pit_df.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(pit_df.info())\n",
    "print(f\"\\nShape: {pit_df.shape}\")\n",
    "print(f\"Columns: {list(pit_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review Driver Data\n",
    "print(\"=\" * 50)\n",
    "print(\"DRIVER DATA REVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(drivers_df.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(drivers_df.info())\n",
    "print(f\"\\nShape: {drivers_df.shape}\")\n",
    "print(f\"Columns: {list(drivers_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We have successfully:\n",
    "1. Connected to the OpenF1 API\n",
    "2. Found the session_key for the Bahrain Grand Prix 2023 Race\n",
    "3. Fetched lap data, pit stop data, and driver information\n",
    "4. Reviewed the structure and content of our datasets\n",
    "\n",
    "This data will serve as the foundation for our F1 simulation model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Now we will prepare our features for the machine learning model. Our initial model will be simple, focusing on the most important predictors of lap times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "print(\"Starting feature engineering...\")\n",
    "print(f\"Initial laps DataFrame shape: {laps_df.shape}\")\n",
    "\n",
    "# Select features and target\n",
    "feature_columns = ['lap_number', 'driver_number', 'tyre_compound']\n",
    "target_column = 'lap_time'\n",
    "\n",
    "# Check if required columns exist\n",
    "missing_columns = [col for col in feature_columns + [target_column] if col not in laps_df.columns]\n",
    "if missing_columns:\n",
    "    print(f\"Warning: Missing columns: {missing_columns}\")\n",
    "    print(f\"Available columns: {list(laps_df.columns)}\")\n",
    "else:\n",
    "    print(\"All required columns found!\")\n",
    "\n",
    "# Create feature DataFrame with selected columns\n",
    "X = laps_df[feature_columns].copy()\n",
    "y = laps_df[target_column].copy()\n",
    "\n",
    "print(f\"\\nFeature DataFrame shape: {X.shape}\")\n",
    "print(f\"Target Series shape: {y.shape}\")\n",
    "\n",
    "# One-hot encode tyre_compound\n",
    "print(\"\\nOne-hot encoding tyre_compound...\")\n",
    "tyre_dummies = pd.get_dummies(X['tyre_compound'], prefix='tyre')\n",
    "print(f\"Tyre compound categories: {list(tyre_dummies.columns)}\")\n",
    "\n",
    "# Create final feature DataFrame\n",
    "X_final = pd.concat([X[['lap_number', 'driver_number']], tyre_dummies], axis=1)\n",
    "\n",
    "print(f\"\\nFinal feature DataFrame shape: {X_final.shape}\")\n",
    "print(f\"Final feature columns: {list(X_final.columns)}\")\n",
    "\n",
    "# Handle missing values\n",
    "print(\"\\nHandling missing values...\")\n",
    "print(f\"Missing values in target: {y.isnull().sum()}\")\n",
    "print(f\"Missing values in features: {X_final.isnull().sum().sum()}\")\n",
    "\n",
    "# Drop rows where lap_time is null\n",
    "valid_indices = y.notna()\n",
    "X_clean = X_final[valid_indices].copy()\n",
    "y_clean = y[valid_indices].copy()\n",
    "\n",
    "print(f\"\\nAfter cleaning - X shape: {X_clean.shape}, y shape: {y_clean.shape}\")\n",
    "print(f\"Data loss: {len(y) - len(y_clean)} rows dropped due to missing lap_time values\")\n",
    "\n",
    "# Display sample of final data\n",
    "print(\"\\nSample of final features:\")\n",
    "print(X_clean.head())\n",
    "print(\"\\nSample of target values:\")\n",
    "print(y_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Now we will train a baseline machine learning model to predict lap times. We'll use LightGBM, which is excellent for tabular data and provides good performance with minimal hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "print(f\"Training data shape: {X_clean.shape}\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_clean, y_clean, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "\n",
    "# Initialize the model\n",
    "model = LGBMRegressor(\n",
    "    random_state=42,\n",
    "    verbose=-1  # Suppress verbose output\n",
    ")\n",
    "\n",
    "print(\"\\nTraining LightGBM model...\")\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training completed!\")\n",
    "print(f\"Number of features used: {model.n_features_in_}\")\n",
    "print(f\"Feature names: {list(model.feature_name_)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation & Saving\n",
    "\n",
    "Now we will evaluate the model's performance and save it for use in our API. We'll calculate the Root Mean Squared Error (RMSE) to assess prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation & Saving\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "print(\"Evaluating model performance...\")\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f} seconds\")\n",
    "\n",
    "# Calculate additional metrics\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f} seconds\")\n",
    "\n",
    "# Calculate R-squared\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared (R²): {r2:.4f}\")\n",
    "\n",
    "# Display some sample predictions\n",
    "print(\"\\nSample predictions vs actual:\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual': y_test.head(10),\n",
    "    'Predicted': y_pred[:10],\n",
    "    'Difference': y_test.head(10) - y_pred[:10]\n",
    "})\n",
    "print(comparison_df)\n",
    "\n",
    "# Save the model\n",
    "print(\"\\nSaving the trained model...\")\n",
    "model_path = \"app/models/lap_time_predictor.joblib\"\n",
    "\n",
    "# Create the models directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"Model saved successfully to: {model_path}\")\n",
    "\n",
    "# Verify the model can be loaded\n",
    "print(\"\\nVerifying model can be loaded...\")\n",
    "loaded_model = joblib.load(model_path)\n",
    "test_prediction = loaded_model.predict(X_test.head(1))\n",
    "print(f\"Test prediction from loaded model: {test_prediction[0]:.4f} seconds\")\n",
    "print(\"Model loading verification successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary\n",
    "\n",
    "We have successfully:\n",
    "1. ✅ Connected to the OpenF1 API and fetched race data\n",
    "2. ✅ Engineered features for lap time prediction\n",
    "3. ✅ Trained a LightGBM regression model\n",
    "4. ✅ Evaluated model performance with RMSE metric\n",
    "5. ✅ Saved the trained model for API use\n",
    "\n",
    "The baseline model is now ready to be used by our F1 What-If Simulator API for predicting lap times based on lap number, driver number, and tyre compound."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}